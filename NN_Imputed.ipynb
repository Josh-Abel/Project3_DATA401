{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **Layers**: an Integer value representing the total number of hidden layers in the network (input and output layers are extra).\n",
    " \n",
    " - **Nodes**: an integer array of size [0,..,Layers+1] containing the dimensions of the neural\n",
    "network. Nodes[0] shall represent the input size (typically, 50), Nodes[Layers+1]\n",
    "shall represent the number of output nodes (typically, 1). All other values Nodes[i]\n",
    "represent the number of nodes in hidden layer i.\n",
    "\n",
    " - **NNodes**: a possible alternative to the Nodes parameter for situations where you want\n",
    "each hidden layer of the neural network to be of the same size. In this case, the size of\n",
    "the output layer is assumed to be 1, and the size of the input layer can be inferred from\n",
    "the dataset.\n",
    "\n",
    " - **Activations**: an array of size [0,..,Layers+1] (for the sake of compatibility) in which\n",
    "Activations[0] and Activations[Layers+1] are not used, while all other\n",
    "Activations[i] values are labels indicating the activation function used in layer i.\n",
    "This allows you to build neural networks with different activation functions in each layer.\n",
    "\n",
    " - **ActivationFn**: a possible alternative to Activations when all hidden layers of your neural\n",
    "network use the same activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    #Layers: an Integer value representing the total number of hidden layers in the network \n",
    "    #        (input and output layers are extra)\n",
    "\n",
    "    def __init__(self, Layers, Nodes, NNodes, Activations, ActivationFn):\n",
    "        self.Layers = Layers\n",
    "        self.Nodes = Nodes\n",
    "        self.NNodes = NNodes\n",
    "        self.Activations = Activations\n",
    "        self.ActivationFn = ActivationFn\n",
    "        \n",
    "    # Forward Pass\n",
    "        \n",
    "    def Relu(self,e):\n",
    "        return max(0,e)\n",
    "    \n",
    "    def leakyRelu(self,e,a=0.1):\n",
    "        if e > 0:\n",
    "            return e\n",
    "        else:\n",
    "            return a*e\n",
    "        \n",
    "    def sigmoid(self,e):\n",
    "        return 1/(1+np.exp(1)**-e)\n",
    "    \n",
    "    def tanh(self,e):\n",
    "        return 2*sigmoid(2*e) - 1\n",
    "    \n",
    "    def applyActivation(self,layer,i):\n",
    "        acttype = self.Activations[i]\n",
    "        if acttype == \"Relu\":\n",
    "            return layer.applymap(self.Relu)\n",
    "        elif acttype == \"leaky\":\n",
    "            return layer.applymap(self.leakyRelu)\n",
    "        elif acttype == \"sigmoid\":\n",
    "            return layer.applymap(self.sigmoid)\n",
    "        elif acttype == \"tanh\":\n",
    "            return layer.applymap(self.tanh)\n",
    "    \n",
    "    def loss(self,z,y):\n",
    "        # Performs L2 loss (for this project)\n",
    "        L = 0.5*(np.array(z)-np.array(y))**2 # Assumes the squaring is element wise\n",
    "        L = np.sum(L) * (1/len(z)) # Take average of all the losses\n",
    "        return L\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    def forward_pass(self, X, y, weights):\n",
    "        # Assume X already has a column of ones for bias term.\n",
    "        # Assume weights include the weights for the bias term when going into next layer\n",
    "        \n",
    "        savings = [X]\n",
    "        \n",
    "        # From input layer to first hidden layer\n",
    "        h = X.dot(weights[0]) # Get first hidden layer without the bias node added in\n",
    "        h['ones'] = 1 # Add in bias node to the hidden layer\n",
    "        savings.append(h) # Saving intermediate values\n",
    "        hact = self.applyActivation(h,0) # Perform activation\n",
    "        hact['ones'] = 1\n",
    "        savings.append(hact) # Saving intermediate values\n",
    "        h = hact\n",
    "     \n",
    "        for i in range(1,len(weights)):\n",
    "            if i != len(weights)-1: # A hidden layer\n",
    "                h = h.dot(weights[i])\n",
    "                h['ones'] = 1 # Add in bias node to the hidden layer\n",
    "                savings.append(h) # Saving intermediate values\n",
    "                hact = self.applyActivation(h,i) # Perform activation\n",
    "                hact['ones'] = 1\n",
    "                savings.append(hact) # Saving intermediate values\n",
    "                h = hact\n",
    "            else: # For Z value/vector\n",
    "                z = h.dot(weights[i])\n",
    "                savings.append(z)\n",
    "                \n",
    "                # Calculate loss\n",
    "                L = self.loss(z,y)\n",
    "                savings.append(L) # Are we saving average loss over the batch?\n",
    "                \n",
    "        return savings\n",
    "    \n",
    "    # Backwards pass\n",
    "        def J_loss(self,z,y):\n",
    "            B = len(y)\n",
    "            J = (1/B)*(np.array(z) - np.array(y))\n",
    "            return J\n",
    "    \n",
    "    def back_propagation(self,X,y,intermediates,weights, lr):\n",
    "        J = self.J_loss(intermediates[-2],y) # Compute the jacobian of the loss layer evaluated at z\n",
    "        w_on = True\n",
    "        w_count = len(weights)-1\n",
    "        for i in range(-3,-len(intermediates),-1):\n",
    "            if w_on:\n",
    "                J_wn = J.dot(self.J_weight(intermediates[i])) # Calculate the jacobian of the weights evaluated at sigma\n",
    "                weights[w_count] = weights[w_count] - lr*J_wn # Update the weights\n",
    "                J = J.dot(self.J_inputlayer(intermediates[i])) # Update jacobian by computing the jacobian of dense layer wrt input\n",
    "                w_count = w_count - 1 # Update the index for the next set of weights\n",
    "                w_on = False # Next derivative evaluated at intermediates[i] will not update the weights\n",
    "            else:\n",
    "                J = J.dot(self.J_sigma(intermediates[i]))\n",
    "                w_on = True\n",
    "        # Update last set of weights (W_1)\n",
    "        J_w1 = J.dot(self.J_weight(intermediates[-len(intermediates)]))\n",
    "        weights[w_count] = weights[w_count] - lr*J_w1\n",
    "        return weights\n",
    "\n",
    "    \n",
    "    # Training\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        weights = []\n",
    "        for i in range(len(self.Nodes)-1):\n",
    "            M = self.Nodes[i] + 1  #+1 for bias term\n",
    "            N = self.Nodes[i+1]  \n",
    "            w = np.random.normal(loc=0,scale = np.sqrt(2/(M+N)),size=(M,N)) \n",
    "            weights.append(w)\n",
    "        return weights\n",
    "    \n",
    "    def train(self,X,y,lr,batch):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/sberbank-russian-housing-market/train.csv')\n",
    "df = df.select_dtypes(exclude=['category', 'object'])\n",
    "df = df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>state</th>\n",
       "      <th>area_m</th>\n",
       "      <th>...</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_4000</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>big_church_count_5000</th>\n",
       "      <th>church_count_5000</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <th>sport_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.141596</td>\n",
       "      <td>-0.690013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.544788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313871</td>\n",
       "      <td>-0.238993</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.070250</td>\n",
       "      <td>-0.174277</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>-0.420245</td>\n",
       "      <td>-0.017208</td>\n",
       "      <td>-0.406425</td>\n",
       "      <td>-0.266324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.531523</td>\n",
       "      <td>-0.294604</td>\n",
       "      <td>-0.877987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.390702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232198</td>\n",
       "      <td>-0.274222</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>-0.026433</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.065654</td>\n",
       "      <td>0.285221</td>\n",
       "      <td>1.638925</td>\n",
       "      <td>-0.234943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.103343</td>\n",
       "      <td>-1.065960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.622239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300259</td>\n",
       "      <td>-0.274222</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.138936</td>\n",
       "      <td>-0.068674</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>-0.225885</td>\n",
       "      <td>0.306823</td>\n",
       "      <td>0.820785</td>\n",
       "      <td>-0.297704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.914671</td>\n",
       "      <td>0.298304</td>\n",
       "      <td>0.249854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.245700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286647</td>\n",
       "      <td>-0.309452</td>\n",
       "      <td>-0.142429</td>\n",
       "      <td>-0.379335</td>\n",
       "      <td>-0.554448</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>-0.420245</td>\n",
       "      <td>-0.578861</td>\n",
       "      <td>-0.610960</td>\n",
       "      <td>1.250402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599138</td>\n",
       "      <td>0.814708</td>\n",
       "      <td>-0.690013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.448374</td>\n",
       "      <td>...</td>\n",
       "      <td>3.905860</td>\n",
       "      <td>3.424887</td>\n",
       "      <td>2.810299</td>\n",
       "      <td>4.119571</td>\n",
       "      <td>4.345529</td>\n",
       "      <td>2.556515</td>\n",
       "      <td>4.001437</td>\n",
       "      <td>3.071885</td>\n",
       "      <td>1.638925</td>\n",
       "      <td>1.926434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30466</th>\n",
       "      <td>-0.268578</td>\n",
       "      <td>-0.141596</td>\n",
       "      <td>-0.126093</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.007080</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>-0.014127</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.368245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232198</td>\n",
       "      <td>-0.203763</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>-0.089795</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>-0.323065</td>\n",
       "      <td>0.674058</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.057942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30467</th>\n",
       "      <td>0.835788</td>\n",
       "      <td>0.470439</td>\n",
       "      <td>-0.877987</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>0.116722</td>\n",
       "      <td>-0.007339</td>\n",
       "      <td>2.453903</td>\n",
       "      <td>0.127389</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.501211</td>\n",
       "      <td>...</td>\n",
       "      <td>3.824188</td>\n",
       "      <td>4.129479</td>\n",
       "      <td>4.102117</td>\n",
       "      <td>2.848887</td>\n",
       "      <td>3.205018</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>3.564128</td>\n",
       "      <td>2.553436</td>\n",
       "      <td>1.843460</td>\n",
       "      <td>3.739925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30468</th>\n",
       "      <td>-0.242284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437827</td>\n",
       "      <td>1.101332</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.068116</td>\n",
       "      <td>-0.191022</td>\n",
       "      <td>-1.257808</td>\n",
       "      <td>0.381575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422767</td>\n",
       "      <td>-0.344682</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.448021</td>\n",
       "      <td>-0.385483</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>-0.371655</td>\n",
       "      <td>-0.902892</td>\n",
       "      <td>-1.020030</td>\n",
       "      <td>-0.031815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30469</th>\n",
       "      <td>0.257310</td>\n",
       "      <td>-0.045965</td>\n",
       "      <td>-0.502040</td>\n",
       "      <td>0.361292</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.006899</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>0.162768</td>\n",
       "      <td>-0.121602</td>\n",
       "      <td>-0.562102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136914</td>\n",
       "      <td>-0.344682</td>\n",
       "      <td>-0.142429</td>\n",
       "      <td>-0.310650</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>-0.225885</td>\n",
       "      <td>0.263619</td>\n",
       "      <td>0.207180</td>\n",
       "      <td>1.334084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30470</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.122469</td>\n",
       "      <td>-1.253934</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.007125</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>-0.014127</td>\n",
       "      <td>-0.121602</td>\n",
       "      <td>-0.642237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368319</td>\n",
       "      <td>-0.309452</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.276307</td>\n",
       "      <td>-0.301000</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>0.017064</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.820785</td>\n",
       "      <td>-0.318624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30471 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        full_sq   life_sq     floor  max_floor  material  build_year  \\\n",
       "0     -0.294873 -0.141596 -0.690013        NaN       NaN         NaN   \n",
       "1     -0.531523 -0.294604 -0.877987        NaN       NaN         NaN   \n",
       "2     -0.294873 -0.103343 -1.065960        NaN       NaN         NaN   \n",
       "3      0.914671  0.298304  0.249854        NaN       NaN         NaN   \n",
       "4      0.599138  0.814708 -0.690013        NaN       NaN         NaN   \n",
       "...         ...       ...       ...        ...       ...         ...   \n",
       "30466 -0.268578 -0.141596 -0.126093  -0.526757 -0.558443   -0.007080   \n",
       "30467  0.835788  0.470439 -0.877987  -0.526757  0.116722   -0.007339   \n",
       "30468 -0.242284       NaN  0.437827   1.101332 -0.558443         NaN   \n",
       "30469  0.257310 -0.045965 -0.502040   0.361292 -0.558443   -0.006899   \n",
       "30470 -0.294873 -0.122469 -1.253934  -0.526757 -0.558443   -0.007125   \n",
       "\n",
       "       num_room  kitch_sq     state    area_m  ...  \\\n",
       "0           NaN       NaN       NaN -0.544788  ...   \n",
       "1           NaN       NaN       NaN -0.390702  ...   \n",
       "2           NaN       NaN       NaN -0.622239  ...   \n",
       "3           NaN       NaN       NaN -0.245700  ...   \n",
       "4           NaN       NaN       NaN -0.448374  ...   \n",
       "...         ...       ...       ...       ...  ...   \n",
       "30466  0.105890 -0.014127  1.014604 -0.368245  ...   \n",
       "30467  2.453903  0.127389  1.014604 -0.501211  ...   \n",
       "30468 -1.068116 -0.191022 -1.257808  0.381575  ...   \n",
       "30469  0.105890  0.162768 -0.121602 -0.562102  ...   \n",
       "30470  0.105890 -0.014127 -0.121602 -0.642237  ...   \n",
       "\n",
       "       cafe_count_5000_price_2500  cafe_count_5000_price_4000  \\\n",
       "0                       -0.313871                   -0.238993   \n",
       "1                       -0.232198                   -0.274222   \n",
       "2                       -0.300259                   -0.274222   \n",
       "3                       -0.286647                   -0.309452   \n",
       "4                        3.905860                    3.424887   \n",
       "...                           ...                         ...   \n",
       "30466                   -0.232198                   -0.203763   \n",
       "30467                    3.824188                    4.129479   \n",
       "30468                   -0.422767                   -0.344682   \n",
       "30469                   -0.136914                   -0.344682   \n",
       "30470                   -0.368319                   -0.309452   \n",
       "\n",
       "       cafe_count_5000_price_high  big_church_count_5000  church_count_5000  \\\n",
       "0                       -0.326975              -0.070250          -0.174277   \n",
       "1                       -0.326975              -0.001564          -0.026433   \n",
       "2                       -0.326975              -0.138936          -0.068674   \n",
       "3                       -0.142429              -0.379335          -0.554448   \n",
       "4                        2.810299               4.119571           4.345529   \n",
       "...                           ...                    ...                ...   \n",
       "30466                   -0.326975              -0.001564          -0.089795   \n",
       "30467                    4.102117               2.848887           3.205018   \n",
       "30468                   -0.326975              -0.448021          -0.385483   \n",
       "30469                   -0.142429              -0.310650           0.015808   \n",
       "30470                   -0.326975              -0.276307          -0.301000   \n",
       "\n",
       "       mosque_count_5000  leisure_count_5000  sport_count_5000  \\\n",
       "0               0.915176           -0.420245         -0.017208   \n",
       "1               0.915176            0.065654          0.285221   \n",
       "2              -0.726162           -0.225885          0.306823   \n",
       "3              -0.726162           -0.420245         -0.578861   \n",
       "4               2.556515            4.001437          3.071885   \n",
       "...                  ...                 ...               ...   \n",
       "30466           0.915176           -0.323065          0.674058   \n",
       "30467           0.915176            3.564128          2.553436   \n",
       "30468          -0.726162           -0.371655         -0.902892   \n",
       "30469           0.915176           -0.225885          0.263619   \n",
       "30470          -0.726162            0.017064          0.025996   \n",
       "\n",
       "       market_count_5000  price_doc  \n",
       "0              -0.406425  -0.266324  \n",
       "1               1.638925  -0.234943  \n",
       "2               0.820785  -0.297704  \n",
       "3              -0.610960   1.250402  \n",
       "4               1.638925   1.926434  \n",
       "...                  ...        ...  \n",
       "30466           0.002645   0.057942  \n",
       "30467           1.843460   3.739925  \n",
       "30468          -1.020030  -0.031815  \n",
       "30469           0.207180   1.334084  \n",
       "30470           0.820785  -0.318624  \n",
       "\n",
       "[30471 rows x 275 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>state</th>\n",
       "      <th>area_m</th>\n",
       "      <th>...</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_4000</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>big_church_count_5000</th>\n",
       "      <th>church_count_5000</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <th>sport_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.141596</td>\n",
       "      <td>-0.690013</td>\n",
       "      <td>-0.378749</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.007087</td>\n",
       "      <td>0.692894</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.544788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313871</td>\n",
       "      <td>-0.238993</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.070250</td>\n",
       "      <td>-0.174277</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>-0.420245</td>\n",
       "      <td>-0.017208</td>\n",
       "      <td>-0.406425</td>\n",
       "      <td>-0.266324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.531523</td>\n",
       "      <td>-0.294604</td>\n",
       "      <td>-0.877987</td>\n",
       "      <td>-0.008729</td>\n",
       "      <td>2.142218</td>\n",
       "      <td>-0.007090</td>\n",
       "      <td>-1.068116</td>\n",
       "      <td>0.074321</td>\n",
       "      <td>0.446501</td>\n",
       "      <td>-0.390702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232198</td>\n",
       "      <td>-0.274222</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>-0.026433</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.065654</td>\n",
       "      <td>0.285221</td>\n",
       "      <td>1.638925</td>\n",
       "      <td>-0.234943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.103343</td>\n",
       "      <td>-1.065960</td>\n",
       "      <td>-0.822773</td>\n",
       "      <td>0.116722</td>\n",
       "      <td>-0.007142</td>\n",
       "      <td>1.279897</td>\n",
       "      <td>-0.067196</td>\n",
       "      <td>-0.121602</td>\n",
       "      <td>-0.622239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300259</td>\n",
       "      <td>-0.274222</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.138936</td>\n",
       "      <td>-0.068674</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>-0.225885</td>\n",
       "      <td>0.306823</td>\n",
       "      <td>0.820785</td>\n",
       "      <td>-0.297704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.914671</td>\n",
       "      <td>0.298304</td>\n",
       "      <td>0.249854</td>\n",
       "      <td>0.657308</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.006931</td>\n",
       "      <td>1.279897</td>\n",
       "      <td>0.162768</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.245700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286647</td>\n",
       "      <td>-0.309452</td>\n",
       "      <td>-0.142429</td>\n",
       "      <td>-0.379335</td>\n",
       "      <td>-0.554448</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>-0.420245</td>\n",
       "      <td>-0.578861</td>\n",
       "      <td>-0.610960</td>\n",
       "      <td>1.250402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599138</td>\n",
       "      <td>0.814708</td>\n",
       "      <td>-0.690013</td>\n",
       "      <td>-0.896777</td>\n",
       "      <td>0.116722</td>\n",
       "      <td>-0.007258</td>\n",
       "      <td>1.866900</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>0.446501</td>\n",
       "      <td>-0.448374</td>\n",
       "      <td>...</td>\n",
       "      <td>3.905860</td>\n",
       "      <td>3.424887</td>\n",
       "      <td>2.810299</td>\n",
       "      <td>4.119571</td>\n",
       "      <td>4.345529</td>\n",
       "      <td>2.556515</td>\n",
       "      <td>4.001437</td>\n",
       "      <td>3.071885</td>\n",
       "      <td>1.638925</td>\n",
       "      <td>1.926434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30466</th>\n",
       "      <td>-0.268578</td>\n",
       "      <td>-0.141596</td>\n",
       "      <td>-0.126093</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.007080</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>-0.014127</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.368245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232198</td>\n",
       "      <td>-0.203763</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>-0.089795</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>-0.323065</td>\n",
       "      <td>0.674058</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.057942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30467</th>\n",
       "      <td>0.835788</td>\n",
       "      <td>0.470439</td>\n",
       "      <td>-0.877987</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>0.116722</td>\n",
       "      <td>-0.007339</td>\n",
       "      <td>2.453903</td>\n",
       "      <td>0.127389</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.501211</td>\n",
       "      <td>...</td>\n",
       "      <td>3.824188</td>\n",
       "      <td>4.129479</td>\n",
       "      <td>4.102117</td>\n",
       "      <td>2.848887</td>\n",
       "      <td>3.205018</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>3.564128</td>\n",
       "      <td>2.553436</td>\n",
       "      <td>1.843460</td>\n",
       "      <td>3.739925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30468</th>\n",
       "      <td>-0.242284</td>\n",
       "      <td>0.135733</td>\n",
       "      <td>0.437827</td>\n",
       "      <td>1.101332</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.019870</td>\n",
       "      <td>-1.068116</td>\n",
       "      <td>-0.191022</td>\n",
       "      <td>-1.257808</td>\n",
       "      <td>0.381575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422767</td>\n",
       "      <td>-0.344682</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.448021</td>\n",
       "      <td>-0.385483</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>-0.371655</td>\n",
       "      <td>-0.902892</td>\n",
       "      <td>-1.020030</td>\n",
       "      <td>-0.031815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30469</th>\n",
       "      <td>0.257310</td>\n",
       "      <td>-0.045965</td>\n",
       "      <td>-0.502040</td>\n",
       "      <td>0.361292</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.006899</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>0.162768</td>\n",
       "      <td>-0.121602</td>\n",
       "      <td>-0.562102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136914</td>\n",
       "      <td>-0.344682</td>\n",
       "      <td>-0.142429</td>\n",
       "      <td>-0.310650</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>-0.225885</td>\n",
       "      <td>0.263619</td>\n",
       "      <td>0.207180</td>\n",
       "      <td>1.334084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30470</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.122469</td>\n",
       "      <td>-1.253934</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.007125</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>-0.014127</td>\n",
       "      <td>-0.121602</td>\n",
       "      <td>-0.642237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368319</td>\n",
       "      <td>-0.309452</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.276307</td>\n",
       "      <td>-0.301000</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>0.017064</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.820785</td>\n",
       "      <td>-0.318624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30471 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        full_sq   life_sq     floor  max_floor  material  build_year  \\\n",
       "0     -0.294873 -0.141596 -0.690013  -0.378749 -0.558443   -0.007087   \n",
       "1     -0.531523 -0.294604 -0.877987  -0.008729  2.142218   -0.007090   \n",
       "2     -0.294873 -0.103343 -1.065960  -0.822773  0.116722   -0.007142   \n",
       "3      0.914671  0.298304  0.249854   0.657308 -0.558443   -0.006931   \n",
       "4      0.599138  0.814708 -0.690013  -0.896777  0.116722   -0.007258   \n",
       "...         ...       ...       ...        ...       ...         ...   \n",
       "30466 -0.268578 -0.141596 -0.126093  -0.526757 -0.558443   -0.007080   \n",
       "30467  0.835788  0.470439 -0.877987  -0.526757  0.116722   -0.007339   \n",
       "30468 -0.242284  0.135733  0.437827   1.101332 -0.558443   -0.019870   \n",
       "30469  0.257310 -0.045965 -0.502040   0.361292 -0.558443   -0.006899   \n",
       "30470 -0.294873 -0.122469 -1.253934  -0.526757 -0.558443   -0.007125   \n",
       "\n",
       "       num_room  kitch_sq     state    area_m  ...  \\\n",
       "0      0.692894  0.021252  1.014604 -0.544788  ...   \n",
       "1     -1.068116  0.074321  0.446501 -0.390702  ...   \n",
       "2      1.279897 -0.067196 -0.121602 -0.622239  ...   \n",
       "3      1.279897  0.162768  1.014604 -0.245700  ...   \n",
       "4      1.866900  0.021252  0.446501 -0.448374  ...   \n",
       "...         ...       ...       ...       ...  ...   \n",
       "30466  0.105890 -0.014127  1.014604 -0.368245  ...   \n",
       "30467  2.453903  0.127389  1.014604 -0.501211  ...   \n",
       "30468 -1.068116 -0.191022 -1.257808  0.381575  ...   \n",
       "30469  0.105890  0.162768 -0.121602 -0.562102  ...   \n",
       "30470  0.105890 -0.014127 -0.121602 -0.642237  ...   \n",
       "\n",
       "       cafe_count_5000_price_2500  cafe_count_5000_price_4000  \\\n",
       "0                       -0.313871                   -0.238993   \n",
       "1                       -0.232198                   -0.274222   \n",
       "2                       -0.300259                   -0.274222   \n",
       "3                       -0.286647                   -0.309452   \n",
       "4                        3.905860                    3.424887   \n",
       "...                           ...                         ...   \n",
       "30466                   -0.232198                   -0.203763   \n",
       "30467                    3.824188                    4.129479   \n",
       "30468                   -0.422767                   -0.344682   \n",
       "30469                   -0.136914                   -0.344682   \n",
       "30470                   -0.368319                   -0.309452   \n",
       "\n",
       "       cafe_count_5000_price_high  big_church_count_5000  church_count_5000  \\\n",
       "0                       -0.326975              -0.070250          -0.174277   \n",
       "1                       -0.326975              -0.001564          -0.026433   \n",
       "2                       -0.326975              -0.138936          -0.068674   \n",
       "3                       -0.142429              -0.379335          -0.554448   \n",
       "4                        2.810299               4.119571           4.345529   \n",
       "...                           ...                    ...                ...   \n",
       "30466                   -0.326975              -0.001564          -0.089795   \n",
       "30467                    4.102117               2.848887           3.205018   \n",
       "30468                   -0.326975              -0.448021          -0.385483   \n",
       "30469                   -0.142429              -0.310650           0.015808   \n",
       "30470                   -0.326975              -0.276307          -0.301000   \n",
       "\n",
       "       mosque_count_5000  leisure_count_5000  sport_count_5000  \\\n",
       "0               0.915176           -0.420245         -0.017208   \n",
       "1               0.915176            0.065654          0.285221   \n",
       "2              -0.726162           -0.225885          0.306823   \n",
       "3              -0.726162           -0.420245         -0.578861   \n",
       "4               2.556515            4.001437          3.071885   \n",
       "...                  ...                 ...               ...   \n",
       "30466           0.915176           -0.323065          0.674058   \n",
       "30467           0.915176            3.564128          2.553436   \n",
       "30468          -0.726162           -0.371655         -0.902892   \n",
       "30469           0.915176           -0.225885          0.263619   \n",
       "30470          -0.726162            0.017064          0.025996   \n",
       "\n",
       "       market_count_5000  price_doc  \n",
       "0              -0.406425  -0.266324  \n",
       "1               1.638925  -0.234943  \n",
       "2               0.820785  -0.297704  \n",
       "3              -0.610960   1.250402  \n",
       "4               1.638925   1.926434  \n",
       "...                  ...        ...  \n",
       "30466           0.002645   0.057942  \n",
       "30467           1.843460   3.739925  \n",
       "30468          -1.020030  -0.031815  \n",
       "30469           0.207180   1.334084  \n",
       "30470           0.820785  -0.318624  \n",
       "\n",
       "[30471 rows x 275 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = set()\n",
    "for col1 in df.columns:\n",
    "    if col1 in remove_cols:\n",
    "        continue\n",
    "        \n",
    "    for col2 in df.columns:\n",
    "        if col1 == col2 or col2 in remove_cols:\n",
    "            continue\n",
    "            \n",
    "        if abs(df_corr[col1][col2]) > 0.80:\n",
    "            remove_cols.add(col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(remove_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(remove_cols), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['timestamp', 'full_sq', 'life_sq', 'floor', 'max_floor', 'material', 'build_year', 'num_room', 'kitch_sq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[[\"sepal_length\", \"sepal_width\", \"petal_length\"]]\n",
    "X['ones'] = 1\n",
    "y = iris[[\"petal_width\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNetwork(Layers=1, Nodes=[3,2,1], NNodes=None, Activations=[\"Relu\",\"Relu\"], ActivationFn=None)\n",
    "weights = NN.initialize_weights()\n",
    "intermediates = NN.forward_pass(X,y,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=130\n",
    "(1/B)*(np.array(intermediates[3]) - np.array(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(e):\n",
    "    return max(0,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leakyRelu(e,a=0.1):\n",
    "    if e > 0:\n",
    "        return e\n",
    "    else:\n",
    "        return a*e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(e):\n",
    "    return 1/(1+np.exp(1)**-e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(e):\n",
    "    return 2*sigmoid(2*e) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = iris.drop('species',axis=1)\n",
    "# b = petal_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.normal(loc=0,scale = np.sqrt(2/(3+3)),size=(3,4))\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w = np.array(df.mean())\n",
    "w = [list(w)]*3\n",
    "w = np.array(w)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = np.array(df.iloc[0])\n",
    "one[len(one)-1] = 1\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = w.dot(one)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(h).apply(tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pd.Series(h).apply(leakyRelu,args=(0.2,))\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = 2\n",
    "w2 = np.array([1,2,3,b2])\n",
    "z = w2.dot(np.append(h,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"petal_width\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = df.dot(w.T).applymap(ReLu)\n",
    "#df.dot(w.T)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[\"ones\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = h.dot(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Loss over batch\n",
    "Lb = 0.5*((z-iris[\"petal_width\"])**2)\n",
    "(1/len(Lb))*np.sum(Lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
