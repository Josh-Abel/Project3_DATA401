{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **Layers**: an Integer value representing the total number of hidden layers in the network (input and output layers are extra).\n",
    " \n",
    " - **Nodes**: an integer array of size [0,..,Layers+1] containing the dimensions of the neural\n",
    "network. Nodes[0] shall represent the input size (typically, 50), Nodes[Layers+1]\n",
    "shall represent the number of output nodes (typically, 1). All other values Nodes[i]\n",
    "represent the number of nodes in hidden layer i.\n",
    "\n",
    " - **NNodes**: a possible alternative to the Nodes parameter for situations where you want\n",
    "each hidden layer of the neural network to be of the same size. In this case, the size of\n",
    "the output layer is assumed to be 1, and the size of the input layer can be inferred from\n",
    "the dataset.\n",
    "\n",
    " - **Activations**: an array of size [0,..,Layers+1] (for the sake of compatibility) in which\n",
    "Activations[0] and Activations[Layers+1] are not used, while all other\n",
    "Activations[i] values are labels indicating the activation function used in layer i.\n",
    "This allows you to build neural networks with different activation functions in each layer.\n",
    "\n",
    " - **ActivationFn**: a possible alternative to Activations when all hidden layers of your neural\n",
    "network use the same activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    #Layers: an Integer value representing the total number of hidden layers in the network \n",
    "    #        (input and output layers are extra)\n",
    "\n",
    "    def __init__(self, Layers, Nodes, NNodes, Activations, ActivationFn, a=None):\n",
    "        self.Layers = Layers\n",
    "        self.Nodes = Nodes\n",
    "        self.NNodes = NNodes\n",
    "        self.Activations = Activations\n",
    "        self.ActivationFn = ActivationFn\n",
    "        self.a = a # The coefficient used if using leaky Relu as the activation function, default is None\n",
    "        self.weights = None\n",
    "        \n",
    "       \n",
    "        \n",
    "    # Forward Pass\n",
    "        \n",
    "    def Relu(self,e):\n",
    "        return max(0,e)\n",
    "    \n",
    "    def leakyRelu(self,e):\n",
    "        if e > 0:\n",
    "            return e\n",
    "        else:\n",
    "            return self.a*e\n",
    "        \n",
    "    def sigmoid(self,e):\n",
    "        return 1/(1+np.exp(1)**-e)\n",
    "    \n",
    "    def tanh(self,e):\n",
    "        return 2*self.sigmoid(2*e) - 1\n",
    "    \n",
    "    def applyActivation(self,layer,i):\n",
    "        acttype = self.Activations[i]\n",
    "        if acttype == \"Relu\":\n",
    "            return layer.applymap(self.Relu)\n",
    "        elif acttype == \"leaky\":\n",
    "            return layer.applymap(self.leakyRelu)\n",
    "        elif acttype == \"sigmoid\":\n",
    "            return layer.applymap(self.sigmoid)\n",
    "        elif acttype == \"tanh\":\n",
    "            return layer.applymap(self.tanh)\n",
    "    \n",
    "    def loss(self,z,y):\n",
    "        # Performs L2 loss (for this project)\n",
    "        L = 0.5*((np.array(z)-np.array(y))**2) # Assumes the squaring is element wise\n",
    "        L = np.sum(L) * (1/len(z)) # Take average of all the losses\n",
    "        return L     \n",
    "        \n",
    "\n",
    "\n",
    "    def forward_pass(self, X, y, weights):\n",
    "            # Assume X already has a column of ones for bias term.\n",
    "            # Assume weights include the weights for the bias term when going into next layer\n",
    "\n",
    "            savings = [X]\n",
    "\n",
    "            # From input layer to first hidden layer\n",
    "            h = X.dot(weights[0]) # Get first hidden layer without the bias node added in\n",
    "            h['ones'] = 1 # Add in bias node to the hidden layer\n",
    "            savings.append(h) # Saving intermediate values\n",
    "            hact = self.applyActivation(h,0) # Perform activation\n",
    "            hact['ones'] = 1\n",
    "            savings.append(hact) # Saving intermediate values\n",
    "            h = hact\n",
    "\n",
    "            for i in range(1,len(weights)):\n",
    "                if i != len(weights)-1: # A hidden layer\n",
    "                    h = h.dot(weights[i])\n",
    "                    h['ones'] = 1 # Add in bias node to the hidden layer\n",
    "                    savings.append(h) # Saving intermediate values\n",
    "                    hact = self.applyActivation(h,i) # Perform activation\n",
    "                    hact['ones'] = 1\n",
    "                    savings.append(hact) # Saving intermediate values\n",
    "                    h = hact\n",
    "                else: # For Z value/vector\n",
    "                    z = h.dot(weights[i])\n",
    "                    savings.append(z)\n",
    "\n",
    "                    # Calculate loss\n",
    "                    L = self.loss(z,y)\n",
    "                    savings.append(L) # Are we saving average loss over the batch?\n",
    "            return savings\n",
    "    \n",
    "    # Backwards pass\n",
    "    def J_loss(self,z,y):\n",
    "        B = len(y)\n",
    "        #print(z.subtract(y,axis=0))\n",
    "        #J = (1/B)*(np.array(z) - np.array(y))\n",
    "        J = (1/B)*(z.subtract(y,axis=0))\n",
    "        return J\n",
    "    \n",
    "    def J_sigma(self, X, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            S = (1/(1+np.exp(-X)))\n",
    "            return S.multiply(1-S)\n",
    "        elif activation == \"tanh\":\n",
    "            return 1-(X**2)\n",
    "        elif activation == \"Relu\":\n",
    "            return (X > 0).astype(int)\n",
    "        elif activation == \"leaky\":\n",
    "            return (X>0).astype(int) +  self.a*(X<0).astype(int)\n",
    "        \n",
    "    def J_inputlayer(self,J,w):\n",
    "        #return J.dot(w.T)\n",
    "        #print(w)\n",
    "        #w = pd.DataFrame(w).drop([len(w)-1],axis=0)\n",
    "        w = pd.DataFrame(w).iloc[:-1]\n",
    "        return J.dot(w.T)\n",
    "    \n",
    "    def J_weight(self,J,X):\n",
    "        return np.array(X.T).dot(J)\n",
    "    \n",
    "    def back_propagation(self,X,y,intermediates,weights,lr,batch):\n",
    "        J = pd.DataFrame(self.J_loss(intermediates[-2],y)) # Compute the jacobian of the loss layer evaluated at z\n",
    "        w_on = True\n",
    "        w_count = len(weights)-1\n",
    "        act_count = len(self.Activations) - 1\n",
    "        for i in range(-3,-len(intermediates),-1):\n",
    "            if w_on:\n",
    "                J_wn = self.J_weight(J,intermediates[i])  # Calculate the jacobian of the weights evaluated at sigma\n",
    "                J = self.J_inputlayer(J,weights[w_count])  # Update jacobian by computing the jacobian of dense layer wrt input\n",
    "                weights[w_count] = weights[w_count] - lr*J_wn*(1/batch) # Update the weights\n",
    "                w_count = w_count - 1 # Update the index for the next set of weights\n",
    "                w_on = False # Next derivative evaluated at intermediates[i] will not update the weights\n",
    "            else:\n",
    "                J = np.multiply(J,self.J_sigma(intermediates[i].drop(\"ones\",axis=1), self.Activations[act_count])) # For activation, we use element-wise multiplication\n",
    "                w_on = True\n",
    "                act_count = act_count-1\n",
    "        # Update last set of weights (W_1)\n",
    "        J_w1 = self.J_weight(J,intermediates[-len(intermediates)])\n",
    "        weights[w_count] = weights[w_count] - lr*J_w1*(1/batch)\n",
    "        return weights\n",
    "\n",
    "    \n",
    "    # Training\n",
    "    \n",
    "    def setup(self,width):\n",
    "        if self.NNodes != None:\n",
    "            self.Nodes = [width] + ([self.NNodes]*self.Layers) + [1]\n",
    "        if self.ActivationFn != None:\n",
    "            self.Activations = [self.ActivationFn]*(self.Layers+1) \n",
    "            \n",
    "\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        weights = []\n",
    "        for i in range(len(self.Nodes)-1):\n",
    "            M = self.Nodes[i] \n",
    "            N = self.Nodes[i+1] \n",
    "            if self.Activations[i] in [\"Relu\",\"leaky\"]:\n",
    "                w = np.random.normal(loc=0,scale = np.sqrt(2/(M)),size=(M,N))\n",
    "                w = np.append(w,[[0]*N], axis=0) # BIAS\n",
    "                weights.append(w)\n",
    "            else:\n",
    "                w = np.random.normal(loc=0,scale = np.sqrt(2/(M+N)),size=(M,N)) \n",
    "                w = np.append(w,[[0]*N], axis=0) #BIAS\n",
    "                weights.append(w)\n",
    "        return weights\n",
    "    \n",
    "    def train(self,X,y,lr,batch,max_epoch,eps):\n",
    "        Xsamp = X.sample(batch)\n",
    "        ysamp = y.loc[Xsamp.index]\n",
    "        Losses = []\n",
    "        \n",
    "        # Set up\n",
    "        self.setup(Xsamp.shape[1])\n",
    "        \n",
    "        # first iteration\n",
    "        epoch = 1\n",
    "        weights = self.initialize_weights()\n",
    "        Xsamp[\"ones\"] = 1\n",
    "        intermediates = self.forward_pass(Xsamp,ysamp,weights)\n",
    "        weights = self.back_propagation(Xsamp,ysamp,intermediates,weights,lr,batch)\n",
    "        L0 = intermediates[-1]\n",
    "        Losses.append(L0)\n",
    "        while(L0 > eps):\n",
    "            Xsamp = X.sample(batch)\n",
    "            ysamp = y.loc[Xsamp.index]\n",
    "            Xsamp[\"ones\"] = 1\n",
    "            intermediates = self.forward_pass(Xsamp,ysamp,weights)\n",
    "            weights = self.back_propagation(Xsamp,ysamp,intermediates,weights,lr,batch)\n",
    "            L0 = intermediates[-1]\n",
    "            Losses.append(L0)\n",
    "            epoch = epoch + 1\n",
    "            if epoch == max_epoch:\n",
    "                break\n",
    "        self.weights = weights\n",
    "        print(\"epoch:\",epoch)\n",
    "        #return L0\n",
    "        return Losses\n",
    "    \n",
    "    def predict(self,X_test,y_test):\n",
    "        X_test[\"ones\"] = 1\n",
    "        intermediates = self.forward_pass(X_test,y_test,self.weights)\n",
    "        predictions = intermediates[-2]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/sberbank-russian-housing-market/train.csv')\n",
    "df = df.select_dtypes(exclude=['category', 'object'])\n",
    "df = df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>state</th>\n",
       "      <th>area_m</th>\n",
       "      <th>...</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_4000</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>big_church_count_5000</th>\n",
       "      <th>church_count_5000</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <th>sport_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.141596</td>\n",
       "      <td>-0.690013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.544788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313871</td>\n",
       "      <td>-0.238993</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.070250</td>\n",
       "      <td>-0.174277</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>-0.420245</td>\n",
       "      <td>-0.017208</td>\n",
       "      <td>-0.406425</td>\n",
       "      <td>-0.266324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.531523</td>\n",
       "      <td>-0.294604</td>\n",
       "      <td>-0.877987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.390702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232198</td>\n",
       "      <td>-0.274222</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>-0.026433</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.065654</td>\n",
       "      <td>0.285221</td>\n",
       "      <td>1.638925</td>\n",
       "      <td>-0.234943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.103343</td>\n",
       "      <td>-1.065960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.622239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300259</td>\n",
       "      <td>-0.274222</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.138936</td>\n",
       "      <td>-0.068674</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>-0.225885</td>\n",
       "      <td>0.306823</td>\n",
       "      <td>0.820785</td>\n",
       "      <td>-0.297704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.914671</td>\n",
       "      <td>0.298304</td>\n",
       "      <td>0.249854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.245700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286647</td>\n",
       "      <td>-0.309452</td>\n",
       "      <td>-0.142429</td>\n",
       "      <td>-0.379335</td>\n",
       "      <td>-0.554448</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>-0.420245</td>\n",
       "      <td>-0.578861</td>\n",
       "      <td>-0.610960</td>\n",
       "      <td>1.250402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599138</td>\n",
       "      <td>0.814708</td>\n",
       "      <td>-0.690013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.448374</td>\n",
       "      <td>...</td>\n",
       "      <td>3.905860</td>\n",
       "      <td>3.424887</td>\n",
       "      <td>2.810299</td>\n",
       "      <td>4.119571</td>\n",
       "      <td>4.345529</td>\n",
       "      <td>2.556515</td>\n",
       "      <td>4.001437</td>\n",
       "      <td>3.071885</td>\n",
       "      <td>1.638925</td>\n",
       "      <td>1.926434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30466</th>\n",
       "      <td>-0.268578</td>\n",
       "      <td>-0.141596</td>\n",
       "      <td>-0.126093</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.007080</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>-0.014127</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.368245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232198</td>\n",
       "      <td>-0.203763</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>-0.089795</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>-0.323065</td>\n",
       "      <td>0.674058</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.057942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30467</th>\n",
       "      <td>0.835788</td>\n",
       "      <td>0.470439</td>\n",
       "      <td>-0.877987</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>0.116722</td>\n",
       "      <td>-0.007339</td>\n",
       "      <td>2.453903</td>\n",
       "      <td>0.127389</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.501211</td>\n",
       "      <td>...</td>\n",
       "      <td>3.824188</td>\n",
       "      <td>4.129479</td>\n",
       "      <td>4.102117</td>\n",
       "      <td>2.848887</td>\n",
       "      <td>3.205018</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>3.564128</td>\n",
       "      <td>2.553436</td>\n",
       "      <td>1.843460</td>\n",
       "      <td>3.739925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30468</th>\n",
       "      <td>-0.242284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437827</td>\n",
       "      <td>1.101332</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.068116</td>\n",
       "      <td>-0.191022</td>\n",
       "      <td>-1.257808</td>\n",
       "      <td>0.381575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422767</td>\n",
       "      <td>-0.344682</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.448021</td>\n",
       "      <td>-0.385483</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>-0.371655</td>\n",
       "      <td>-0.902892</td>\n",
       "      <td>-1.020030</td>\n",
       "      <td>-0.031815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30469</th>\n",
       "      <td>0.257310</td>\n",
       "      <td>-0.045965</td>\n",
       "      <td>-0.502040</td>\n",
       "      <td>0.361292</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.006899</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>0.162768</td>\n",
       "      <td>-0.121602</td>\n",
       "      <td>-0.562102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136914</td>\n",
       "      <td>-0.344682</td>\n",
       "      <td>-0.142429</td>\n",
       "      <td>-0.310650</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>-0.225885</td>\n",
       "      <td>0.263619</td>\n",
       "      <td>0.207180</td>\n",
       "      <td>1.334084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30470</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.122469</td>\n",
       "      <td>-1.253934</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.007125</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>-0.014127</td>\n",
       "      <td>-0.121602</td>\n",
       "      <td>-0.642237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368319</td>\n",
       "      <td>-0.309452</td>\n",
       "      <td>-0.326975</td>\n",
       "      <td>-0.276307</td>\n",
       "      <td>-0.301000</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>0.017064</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.820785</td>\n",
       "      <td>-0.318624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30471 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        full_sq   life_sq     floor  max_floor  material  build_year  \\\n",
       "0     -0.294873 -0.141596 -0.690013        NaN       NaN         NaN   \n",
       "1     -0.531523 -0.294604 -0.877987        NaN       NaN         NaN   \n",
       "2     -0.294873 -0.103343 -1.065960        NaN       NaN         NaN   \n",
       "3      0.914671  0.298304  0.249854        NaN       NaN         NaN   \n",
       "4      0.599138  0.814708 -0.690013        NaN       NaN         NaN   \n",
       "...         ...       ...       ...        ...       ...         ...   \n",
       "30466 -0.268578 -0.141596 -0.126093  -0.526757 -0.558443   -0.007080   \n",
       "30467  0.835788  0.470439 -0.877987  -0.526757  0.116722   -0.007339   \n",
       "30468 -0.242284       NaN  0.437827   1.101332 -0.558443         NaN   \n",
       "30469  0.257310 -0.045965 -0.502040   0.361292 -0.558443   -0.006899   \n",
       "30470 -0.294873 -0.122469 -1.253934  -0.526757 -0.558443   -0.007125   \n",
       "\n",
       "       num_room  kitch_sq     state    area_m  ...  \\\n",
       "0           NaN       NaN       NaN -0.544788  ...   \n",
       "1           NaN       NaN       NaN -0.390702  ...   \n",
       "2           NaN       NaN       NaN -0.622239  ...   \n",
       "3           NaN       NaN       NaN -0.245700  ...   \n",
       "4           NaN       NaN       NaN -0.448374  ...   \n",
       "...         ...       ...       ...       ...  ...   \n",
       "30466  0.105890 -0.014127  1.014604 -0.368245  ...   \n",
       "30467  2.453903  0.127389  1.014604 -0.501211  ...   \n",
       "30468 -1.068116 -0.191022 -1.257808  0.381575  ...   \n",
       "30469  0.105890  0.162768 -0.121602 -0.562102  ...   \n",
       "30470  0.105890 -0.014127 -0.121602 -0.642237  ...   \n",
       "\n",
       "       cafe_count_5000_price_2500  cafe_count_5000_price_4000  \\\n",
       "0                       -0.313871                   -0.238993   \n",
       "1                       -0.232198                   -0.274222   \n",
       "2                       -0.300259                   -0.274222   \n",
       "3                       -0.286647                   -0.309452   \n",
       "4                        3.905860                    3.424887   \n",
       "...                           ...                         ...   \n",
       "30466                   -0.232198                   -0.203763   \n",
       "30467                    3.824188                    4.129479   \n",
       "30468                   -0.422767                   -0.344682   \n",
       "30469                   -0.136914                   -0.344682   \n",
       "30470                   -0.368319                   -0.309452   \n",
       "\n",
       "       cafe_count_5000_price_high  big_church_count_5000  church_count_5000  \\\n",
       "0                       -0.326975              -0.070250          -0.174277   \n",
       "1                       -0.326975              -0.001564          -0.026433   \n",
       "2                       -0.326975              -0.138936          -0.068674   \n",
       "3                       -0.142429              -0.379335          -0.554448   \n",
       "4                        2.810299               4.119571           4.345529   \n",
       "...                           ...                    ...                ...   \n",
       "30466                   -0.326975              -0.001564          -0.089795   \n",
       "30467                    4.102117               2.848887           3.205018   \n",
       "30468                   -0.326975              -0.448021          -0.385483   \n",
       "30469                   -0.142429              -0.310650           0.015808   \n",
       "30470                   -0.326975              -0.276307          -0.301000   \n",
       "\n",
       "       mosque_count_5000  leisure_count_5000  sport_count_5000  \\\n",
       "0               0.915176           -0.420245         -0.017208   \n",
       "1               0.915176            0.065654          0.285221   \n",
       "2              -0.726162           -0.225885          0.306823   \n",
       "3              -0.726162           -0.420245         -0.578861   \n",
       "4               2.556515            4.001437          3.071885   \n",
       "...                  ...                 ...               ...   \n",
       "30466           0.915176           -0.323065          0.674058   \n",
       "30467           0.915176            3.564128          2.553436   \n",
       "30468          -0.726162           -0.371655         -0.902892   \n",
       "30469           0.915176           -0.225885          0.263619   \n",
       "30470          -0.726162            0.017064          0.025996   \n",
       "\n",
       "       market_count_5000  price_doc  \n",
       "0              -0.406425  -0.266324  \n",
       "1               1.638925  -0.234943  \n",
       "2               0.820785  -0.297704  \n",
       "3              -0.610960   1.250402  \n",
       "4               1.638925   1.926434  \n",
       "...                  ...        ...  \n",
       "30466           0.002645   0.057942  \n",
       "30467           1.843460   3.739925  \n",
       "30468          -1.020030  -0.031815  \n",
       "30469           0.207180   1.334084  \n",
       "30470           0.820785  -0.318624  \n",
       "\n",
       "[30471 rows x 275 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>state</th>\n",
       "      <th>area_m</th>\n",
       "      <th>...</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_4000</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>big_church_count_5000</th>\n",
       "      <th>church_count_5000</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <th>sport_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full_sq</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161112</td>\n",
       "      <td>0.089649</td>\n",
       "      <td>0.119225</td>\n",
       "      <td>0.032866</td>\n",
       "      <td>-0.006041</td>\n",
       "      <td>0.695444</td>\n",
       "      <td>0.020026</td>\n",
       "      <td>-0.091348</td>\n",
       "      <td>0.056303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039083</td>\n",
       "      <td>0.040059</td>\n",
       "      <td>0.043560</td>\n",
       "      <td>0.026895</td>\n",
       "      <td>0.028579</td>\n",
       "      <td>0.021568</td>\n",
       "      <td>0.030218</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>-0.041254</td>\n",
       "      <td>0.341840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life_sq</th>\n",
       "      <td>0.161112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045090</td>\n",
       "      <td>0.042442</td>\n",
       "      <td>0.011393</td>\n",
       "      <td>-0.002401</td>\n",
       "      <td>0.191024</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.066633</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028735</td>\n",
       "      <td>0.031551</td>\n",
       "      <td>0.034888</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>0.018114</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>0.022737</td>\n",
       "      <td>-0.014499</td>\n",
       "      <td>-0.050337</td>\n",
       "      <td>0.165606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floor</th>\n",
       "      <td>0.089649</td>\n",
       "      <td>0.045090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454488</td>\n",
       "      <td>-0.009043</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>-0.005657</td>\n",
       "      <td>-0.008457</td>\n",
       "      <td>-0.113906</td>\n",
       "      <td>-0.019448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034791</td>\n",
       "      <td>-0.029636</td>\n",
       "      <td>-0.022303</td>\n",
       "      <td>-0.044398</td>\n",
       "      <td>-0.045614</td>\n",
       "      <td>-0.012256</td>\n",
       "      <td>-0.044236</td>\n",
       "      <td>-0.102101</td>\n",
       "      <td>-0.123843</td>\n",
       "      <td>0.117447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_floor</th>\n",
       "      <td>0.119225</td>\n",
       "      <td>0.042442</td>\n",
       "      <td>0.454488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045915</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>-0.014220</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>-0.072161</td>\n",
       "      <td>-0.092954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040235</td>\n",
       "      <td>-0.033662</td>\n",
       "      <td>-0.029525</td>\n",
       "      <td>-0.048235</td>\n",
       "      <td>-0.048240</td>\n",
       "      <td>-0.058255</td>\n",
       "      <td>-0.048664</td>\n",
       "      <td>-0.099855</td>\n",
       "      <td>-0.113341</td>\n",
       "      <td>0.094386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material</th>\n",
       "      <td>0.032866</td>\n",
       "      <td>0.011393</td>\n",
       "      <td>-0.009043</td>\n",
       "      <td>0.045915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004402</td>\n",
       "      <td>-0.026924</td>\n",
       "      <td>0.038747</td>\n",
       "      <td>-0.034225</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050919</td>\n",
       "      <td>0.043660</td>\n",
       "      <td>0.044403</td>\n",
       "      <td>0.038480</td>\n",
       "      <td>0.044701</td>\n",
       "      <td>0.050355</td>\n",
       "      <td>0.044502</td>\n",
       "      <td>0.098482</td>\n",
       "      <td>0.076378</td>\n",
       "      <td>0.064047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <td>0.021568</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>-0.012256</td>\n",
       "      <td>-0.058255</td>\n",
       "      <td>0.050355</td>\n",
       "      <td>0.019631</td>\n",
       "      <td>0.062785</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>0.091894</td>\n",
       "      <td>-0.086786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529434</td>\n",
       "      <td>0.492859</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.502028</td>\n",
       "      <td>0.550342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499376</td>\n",
       "      <td>0.518500</td>\n",
       "      <td>0.242078</td>\n",
       "      <td>0.175107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <td>0.030218</td>\n",
       "      <td>0.022737</td>\n",
       "      <td>-0.044236</td>\n",
       "      <td>-0.048664</td>\n",
       "      <td>0.044502</td>\n",
       "      <td>-0.000830</td>\n",
       "      <td>0.058663</td>\n",
       "      <td>-0.006259</td>\n",
       "      <td>-0.003876</td>\n",
       "      <td>-0.195067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986206</td>\n",
       "      <td>0.975462</td>\n",
       "      <td>0.948391</td>\n",
       "      <td>0.969029</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>0.499376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809169</td>\n",
       "      <td>0.463053</td>\n",
       "      <td>0.200448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport_count_5000</th>\n",
       "      <td>0.001580</td>\n",
       "      <td>-0.014499</td>\n",
       "      <td>-0.102101</td>\n",
       "      <td>-0.099855</td>\n",
       "      <td>0.098482</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>0.089908</td>\n",
       "      <td>0.016866</td>\n",
       "      <td>0.194379</td>\n",
       "      <td>-0.416222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824139</td>\n",
       "      <td>0.778770</td>\n",
       "      <td>0.753384</td>\n",
       "      <td>0.825883</td>\n",
       "      <td>0.847771</td>\n",
       "      <td>0.518500</td>\n",
       "      <td>0.809169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733897</td>\n",
       "      <td>0.294864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_count_5000</th>\n",
       "      <td>-0.041254</td>\n",
       "      <td>-0.050337</td>\n",
       "      <td>-0.123843</td>\n",
       "      <td>-0.113341</td>\n",
       "      <td>0.076378</td>\n",
       "      <td>0.007362</td>\n",
       "      <td>0.061674</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.273385</td>\n",
       "      <td>-0.449849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432265</td>\n",
       "      <td>0.380154</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.482547</td>\n",
       "      <td>0.514344</td>\n",
       "      <td>0.242078</td>\n",
       "      <td>0.463053</td>\n",
       "      <td>0.733897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_doc</th>\n",
       "      <td>0.341840</td>\n",
       "      <td>0.165606</td>\n",
       "      <td>0.117447</td>\n",
       "      <td>0.094386</td>\n",
       "      <td>0.064047</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.476337</td>\n",
       "      <td>0.028718</td>\n",
       "      <td>0.121303</td>\n",
       "      <td>-0.166981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225566</td>\n",
       "      <td>0.210354</td>\n",
       "      <td>0.214327</td>\n",
       "      <td>0.198827</td>\n",
       "      <td>0.213275</td>\n",
       "      <td>0.175107</td>\n",
       "      <td>0.200448</td>\n",
       "      <td>0.294864</td>\n",
       "      <td>0.194021</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     full_sq   life_sq     floor  max_floor  material  \\\n",
       "full_sq             1.000000  0.161112  0.089649   0.119225  0.032866   \n",
       "life_sq             0.161112  1.000000  0.045090   0.042442  0.011393   \n",
       "floor               0.089649  0.045090  1.000000   0.454488 -0.009043   \n",
       "max_floor           0.119225  0.042442  0.454488   1.000000  0.045915   \n",
       "material            0.032866  0.011393 -0.009043   0.045915  1.000000   \n",
       "...                      ...       ...       ...        ...       ...   \n",
       "mosque_count_5000   0.021568  0.009945 -0.012256  -0.058255  0.050355   \n",
       "leisure_count_5000  0.030218  0.022737 -0.044236  -0.048664  0.044502   \n",
       "sport_count_5000    0.001580 -0.014499 -0.102101  -0.099855  0.098482   \n",
       "market_count_5000  -0.041254 -0.050337 -0.123843  -0.113341  0.076378   \n",
       "price_doc           0.341840  0.165606  0.117447   0.094386  0.064047   \n",
       "\n",
       "                    build_year  num_room  kitch_sq     state    area_m  ...  \\\n",
       "full_sq              -0.006041  0.695444  0.020026 -0.091348  0.056303  ...   \n",
       "life_sq              -0.002401  0.191024  0.000633 -0.066633  0.061395  ...   \n",
       "floor                 0.001192 -0.005657 -0.008457 -0.113906 -0.019448  ...   \n",
       "max_floor            -0.000261 -0.014220  0.020345 -0.072161 -0.092954  ...   \n",
       "material             -0.004402 -0.026924  0.038747 -0.034225  0.001182  ...   \n",
       "...                        ...       ...       ...       ...       ...  ...   \n",
       "mosque_count_5000     0.019631  0.062785  0.013183  0.091894 -0.086786  ...   \n",
       "leisure_count_5000   -0.000830  0.058663 -0.006259 -0.003876 -0.195067  ...   \n",
       "sport_count_5000      0.005978  0.089908  0.016866  0.194379 -0.416222  ...   \n",
       "market_count_5000     0.007362  0.061674  0.026404  0.273385 -0.449849  ...   \n",
       "price_doc             0.002161  0.476337  0.028718  0.121303 -0.166981  ...   \n",
       "\n",
       "                    cafe_count_5000_price_2500  cafe_count_5000_price_4000  \\\n",
       "full_sq                               0.039083                    0.040059   \n",
       "life_sq                               0.028735                    0.031551   \n",
       "floor                                -0.034791                   -0.029636   \n",
       "max_floor                            -0.040235                   -0.033662   \n",
       "material                              0.050919                    0.043660   \n",
       "...                                        ...                         ...   \n",
       "mosque_count_5000                     0.529434                    0.492859   \n",
       "leisure_count_5000                    0.986206                    0.975462   \n",
       "sport_count_5000                      0.824139                    0.778770   \n",
       "market_count_5000                     0.432265                    0.380154   \n",
       "price_doc                             0.225566                    0.210354   \n",
       "\n",
       "                    cafe_count_5000_price_high  big_church_count_5000  \\\n",
       "full_sq                               0.043560               0.026895   \n",
       "life_sq                               0.034888               0.017845   \n",
       "floor                                -0.022303              -0.044398   \n",
       "max_floor                            -0.029525              -0.048235   \n",
       "material                              0.044403               0.038480   \n",
       "...                                        ...                    ...   \n",
       "mosque_count_5000                     0.481481               0.502028   \n",
       "leisure_count_5000                    0.948391               0.969029   \n",
       "sport_count_5000                      0.753384               0.825883   \n",
       "market_count_5000                     0.353270               0.482547   \n",
       "price_doc                             0.214327               0.198827   \n",
       "\n",
       "                    church_count_5000  mosque_count_5000  leisure_count_5000  \\\n",
       "full_sq                      0.028579           0.021568            0.030218   \n",
       "life_sq                      0.018114           0.009945            0.022737   \n",
       "floor                       -0.045614          -0.012256           -0.044236   \n",
       "max_floor                   -0.048240          -0.058255           -0.048664   \n",
       "material                     0.044701           0.050355            0.044502   \n",
       "...                               ...                ...                 ...   \n",
       "mosque_count_5000            0.550342           1.000000            0.499376   \n",
       "leisure_count_5000           0.975259           0.499376            1.000000   \n",
       "sport_count_5000             0.847771           0.518500            0.809169   \n",
       "market_count_5000            0.514344           0.242078            0.463053   \n",
       "price_doc                    0.213275           0.175107            0.200448   \n",
       "\n",
       "                    sport_count_5000  market_count_5000  price_doc  \n",
       "full_sq                     0.001580          -0.041254   0.341840  \n",
       "life_sq                    -0.014499          -0.050337   0.165606  \n",
       "floor                      -0.102101          -0.123843   0.117447  \n",
       "max_floor                  -0.099855          -0.113341   0.094386  \n",
       "material                    0.098482           0.076378   0.064047  \n",
       "...                              ...                ...        ...  \n",
       "mosque_count_5000           0.518500           0.242078   0.175107  \n",
       "leisure_count_5000          0.809169           0.463053   0.200448  \n",
       "sport_count_5000            1.000000           0.733897   0.294864  \n",
       "market_count_5000           0.733897           1.000000   0.194021  \n",
       "price_doc                   0.294864           0.194021   1.000000  \n",
       "\n",
       "[275 rows x 275 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr = df.corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = set()\n",
    "for col1 in df.columns:\n",
    "    if col1 in remove_cols or col1 == 'price_doc':\n",
    "        continue\n",
    "        \n",
    "    for col2 in df.columns:\n",
    "        if col1 == col2 or col2 in remove_cols or col2 == 'price_doc':\n",
    "            continue\n",
    "            \n",
    "        if abs(df_corr[col1][col2]) > 0.75:\n",
    "            remove_cols.add(col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(list(remove_cols), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>state</th>\n",
       "      <th>area_m</th>\n",
       "      <th>...</th>\n",
       "      <th>market_count_2000</th>\n",
       "      <th>prom_part_3000</th>\n",
       "      <th>cafe_sum_3000_min_price_avg</th>\n",
       "      <th>mosque_count_3000</th>\n",
       "      <th>green_part_5000</th>\n",
       "      <th>trc_sqm_5000</th>\n",
       "      <th>cafe_sum_5000_min_price_avg</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.141596</td>\n",
       "      <td>-0.690013</td>\n",
       "      <td>-0.378749</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.007087</td>\n",
       "      <td>0.692894</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.544788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118758</td>\n",
       "      <td>0.324073</td>\n",
       "      <td>-0.563478</td>\n",
       "      <td>-0.444553</td>\n",
       "      <td>-0.863607</td>\n",
       "      <td>2.849088</td>\n",
       "      <td>-0.370906</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>-0.406425</td>\n",
       "      <td>-0.266324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.531523</td>\n",
       "      <td>-0.294604</td>\n",
       "      <td>-0.877987</td>\n",
       "      <td>-0.008729</td>\n",
       "      <td>2.142218</td>\n",
       "      <td>-0.007090</td>\n",
       "      <td>-1.068116</td>\n",
       "      <td>0.074321</td>\n",
       "      <td>0.446501</td>\n",
       "      <td>-0.390702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815729</td>\n",
       "      <td>2.058742</td>\n",
       "      <td>-0.602093</td>\n",
       "      <td>-0.444553</td>\n",
       "      <td>-1.116099</td>\n",
       "      <td>0.856963</td>\n",
       "      <td>-0.598980</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>1.638925</td>\n",
       "      <td>-0.234943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.103343</td>\n",
       "      <td>-1.065960</td>\n",
       "      <td>-0.822773</td>\n",
       "      <td>0.116722</td>\n",
       "      <td>-0.007142</td>\n",
       "      <td>1.279897</td>\n",
       "      <td>-0.067196</td>\n",
       "      <td>-0.121602</td>\n",
       "      <td>-0.622239</td>\n",
       "      <td>...</td>\n",
       "      <td>2.669128</td>\n",
       "      <td>1.950404</td>\n",
       "      <td>-0.305624</td>\n",
       "      <td>-0.444553</td>\n",
       "      <td>-0.810075</td>\n",
       "      <td>0.397215</td>\n",
       "      <td>-0.409553</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>0.820785</td>\n",
       "      <td>-0.297704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.914671</td>\n",
       "      <td>0.298304</td>\n",
       "      <td>0.249854</td>\n",
       "      <td>0.657308</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.006931</td>\n",
       "      <td>1.279897</td>\n",
       "      <td>0.162768</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.245700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578213</td>\n",
       "      <td>-0.933153</td>\n",
       "      <td>-0.210491</td>\n",
       "      <td>-0.444553</td>\n",
       "      <td>-0.766358</td>\n",
       "      <td>-0.230586</td>\n",
       "      <td>1.092352</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>-0.610960</td>\n",
       "      <td>1.250402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599138</td>\n",
       "      <td>0.814708</td>\n",
       "      <td>-0.690013</td>\n",
       "      <td>-0.822773</td>\n",
       "      <td>1.129470</td>\n",
       "      <td>-0.007242</td>\n",
       "      <td>1.279897</td>\n",
       "      <td>-0.067196</td>\n",
       "      <td>0.446501</td>\n",
       "      <td>-0.448374</td>\n",
       "      <td>...</td>\n",
       "      <td>1.275185</td>\n",
       "      <td>-0.296981</td>\n",
       "      <td>0.388965</td>\n",
       "      <td>1.788546</td>\n",
       "      <td>-1.283832</td>\n",
       "      <td>2.318075</td>\n",
       "      <td>0.582531</td>\n",
       "      <td>2.556515</td>\n",
       "      <td>1.638925</td>\n",
       "      <td>1.926434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30466</th>\n",
       "      <td>-0.268578</td>\n",
       "      <td>-0.141596</td>\n",
       "      <td>-0.126093</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.007080</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>-0.014127</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.368245</td>\n",
       "      <td>...</td>\n",
       "      <td>1.275185</td>\n",
       "      <td>1.294077</td>\n",
       "      <td>-0.526826</td>\n",
       "      <td>1.788546</td>\n",
       "      <td>-0.646803</td>\n",
       "      <td>1.367864</td>\n",
       "      <td>-0.493079</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.057942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30467</th>\n",
       "      <td>0.835788</td>\n",
       "      <td>0.470439</td>\n",
       "      <td>-0.877987</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>0.116722</td>\n",
       "      <td>-0.007339</td>\n",
       "      <td>2.453903</td>\n",
       "      <td>0.127389</td>\n",
       "      <td>1.014604</td>\n",
       "      <td>-0.501211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578213</td>\n",
       "      <td>0.046929</td>\n",
       "      <td>0.580079</td>\n",
       "      <td>1.788546</td>\n",
       "      <td>-1.291862</td>\n",
       "      <td>3.156912</td>\n",
       "      <td>0.802667</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>1.843460</td>\n",
       "      <td>3.739925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30468</th>\n",
       "      <td>-0.242284</td>\n",
       "      <td>0.135733</td>\n",
       "      <td>0.437827</td>\n",
       "      <td>1.101332</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.019870</td>\n",
       "      <td>-1.068116</td>\n",
       "      <td>-0.191022</td>\n",
       "      <td>-1.257808</td>\n",
       "      <td>0.381575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815729</td>\n",
       "      <td>-1.117076</td>\n",
       "      <td>-0.294195</td>\n",
       "      <td>-0.444553</td>\n",
       "      <td>1.146513</td>\n",
       "      <td>-0.967931</td>\n",
       "      <td>-0.116324</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>-1.020030</td>\n",
       "      <td>-0.031815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30469</th>\n",
       "      <td>0.257310</td>\n",
       "      <td>-0.045965</td>\n",
       "      <td>-0.502040</td>\n",
       "      <td>0.361292</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.006899</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>0.162768</td>\n",
       "      <td>-0.121602</td>\n",
       "      <td>-0.562102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578213</td>\n",
       "      <td>-1.197699</td>\n",
       "      <td>-0.376873</td>\n",
       "      <td>1.788546</td>\n",
       "      <td>0.677217</td>\n",
       "      <td>0.289263</td>\n",
       "      <td>-0.406141</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.207180</td>\n",
       "      <td>1.334084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30470</th>\n",
       "      <td>-0.294873</td>\n",
       "      <td>-0.122469</td>\n",
       "      <td>-1.253934</td>\n",
       "      <td>-0.526757</td>\n",
       "      <td>-0.558443</td>\n",
       "      <td>-0.007125</td>\n",
       "      <td>0.105890</td>\n",
       "      <td>-0.014127</td>\n",
       "      <td>-0.121602</td>\n",
       "      <td>-0.642237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578213</td>\n",
       "      <td>-0.895360</td>\n",
       "      <td>-0.760038</td>\n",
       "      <td>-0.444553</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>-0.524781</td>\n",
       "      <td>-0.660461</td>\n",
       "      <td>-0.726162</td>\n",
       "      <td>0.820785</td>\n",
       "      <td>-0.318624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30471 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        full_sq   life_sq     floor  max_floor  material  build_year  \\\n",
       "0     -0.294873 -0.141596 -0.690013  -0.378749 -0.558443   -0.007087   \n",
       "1     -0.531523 -0.294604 -0.877987  -0.008729  2.142218   -0.007090   \n",
       "2     -0.294873 -0.103343 -1.065960  -0.822773  0.116722   -0.007142   \n",
       "3      0.914671  0.298304  0.249854   0.657308 -0.558443   -0.006931   \n",
       "4      0.599138  0.814708 -0.690013  -0.822773  1.129470   -0.007242   \n",
       "...         ...       ...       ...        ...       ...         ...   \n",
       "30466 -0.268578 -0.141596 -0.126093  -0.526757 -0.558443   -0.007080   \n",
       "30467  0.835788  0.470439 -0.877987  -0.526757  0.116722   -0.007339   \n",
       "30468 -0.242284  0.135733  0.437827   1.101332 -0.558443   -0.019870   \n",
       "30469  0.257310 -0.045965 -0.502040   0.361292 -0.558443   -0.006899   \n",
       "30470 -0.294873 -0.122469 -1.253934  -0.526757 -0.558443   -0.007125   \n",
       "\n",
       "       num_room  kitch_sq     state    area_m  ...  market_count_2000  \\\n",
       "0      0.692894  0.021252  1.014604 -0.544788  ...          -0.118758   \n",
       "1     -1.068116  0.074321  0.446501 -0.390702  ...          -0.815729   \n",
       "2      1.279897 -0.067196 -0.121602 -0.622239  ...           2.669128   \n",
       "3      1.279897  0.162768  1.014604 -0.245700  ...           0.578213   \n",
       "4      1.279897 -0.067196  0.446501 -0.448374  ...           1.275185   \n",
       "...         ...       ...       ...       ...  ...                ...   \n",
       "30466  0.105890 -0.014127  1.014604 -0.368245  ...           1.275185   \n",
       "30467  2.453903  0.127389  1.014604 -0.501211  ...           0.578213   \n",
       "30468 -1.068116 -0.191022 -1.257808  0.381575  ...          -0.815729   \n",
       "30469  0.105890  0.162768 -0.121602 -0.562102  ...           0.578213   \n",
       "30470  0.105890 -0.014127 -0.121602 -0.642237  ...           0.578213   \n",
       "\n",
       "       prom_part_3000  cafe_sum_3000_min_price_avg  mosque_count_3000  \\\n",
       "0            0.324073                    -0.563478          -0.444553   \n",
       "1            2.058742                    -0.602093          -0.444553   \n",
       "2            1.950404                    -0.305624          -0.444553   \n",
       "3           -0.933153                    -0.210491          -0.444553   \n",
       "4           -0.296981                     0.388965           1.788546   \n",
       "...               ...                          ...                ...   \n",
       "30466        1.294077                    -0.526826           1.788546   \n",
       "30467        0.046929                     0.580079           1.788546   \n",
       "30468       -1.117076                    -0.294195          -0.444553   \n",
       "30469       -1.197699                    -0.376873           1.788546   \n",
       "30470       -0.895360                    -0.760038          -0.444553   \n",
       "\n",
       "       green_part_5000  trc_sqm_5000  cafe_sum_5000_min_price_avg  \\\n",
       "0            -0.863607      2.849088                    -0.370906   \n",
       "1            -1.116099      0.856963                    -0.598980   \n",
       "2            -0.810075      0.397215                    -0.409553   \n",
       "3            -0.766358     -0.230586                     1.092352   \n",
       "4            -1.283832      2.318075                     0.582531   \n",
       "...                ...           ...                          ...   \n",
       "30466        -0.646803      1.367864                    -0.493079   \n",
       "30467        -1.291862      3.156912                     0.802667   \n",
       "30468         1.146513     -0.967931                    -0.116324   \n",
       "30469         0.677217      0.289263                    -0.406141   \n",
       "30470         0.207921     -0.524781                    -0.660461   \n",
       "\n",
       "       mosque_count_5000  market_count_5000  price_doc  \n",
       "0               0.915176          -0.406425  -0.266324  \n",
       "1               0.915176           1.638925  -0.234943  \n",
       "2              -0.726162           0.820785  -0.297704  \n",
       "3              -0.726162          -0.610960   1.250402  \n",
       "4               2.556515           1.638925   1.926434  \n",
       "...                  ...                ...        ...  \n",
       "30466           0.915176           0.002645   0.057942  \n",
       "30467           0.915176           1.843460   3.739925  \n",
       "30468          -0.726162          -1.020030  -0.031815  \n",
       "30469           0.915176           0.207180   1.334084  \n",
       "30470          -0.726162           0.820785  -0.318624  \n",
       "\n",
       "[30471 rows x 94 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dot product shape mismatch, (2048, 94) vs (31, 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-705379ee4ad0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNNodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivationFn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Relu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0000001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0melapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time (minutes) elapsed for this cell:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melapsed\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-d93a8cf6eb78>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, lr, batch, max_epoch, eps)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mXsamp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ones\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mintermediates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXsamp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mysamp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXsamp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mysamp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mintermediates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mL0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintermediates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-d93a8cf6eb78>\u001b[0m in \u001b[0;36mforward_pass\u001b[1;34m(self, X, y, weights)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;31m# From input layer to first hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Get first hidden layer without the bias node added in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ones'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;31m# Add in bias node to the hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0msavings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Saving intermediate values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arman\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1087\u001b[0m             \u001b[0mrvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlvals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mrvals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1090\u001b[0m                     \u001b[1;34m\"Dot product shape mismatch, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m                     \u001b[1;34m\"{s} vs {r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlvals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrvals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dot product shape mismatch, (2048, 94) vs (31, 30)"
     ]
    }
   ],
   "source": [
    "X = df.drop('price_doc', axis=1)\n",
    "y = df['price_doc']\n",
    "\n",
    "X_train = X.iloc[:int(16610/2)]\n",
    "y_train = y.iloc[:int(16610/2)]\n",
    "X_test = X.iloc[int(16610/2)+1:]\n",
    "y_test = y.iloc[int(16610/2)+1:]\n",
    "\n",
    "NN = NeuralNetwork(Layers=4, Nodes=[30,30,30,20,10,1], NNodes=None, Activations=None, ActivationFn=\"Relu\", a=None)\n",
    "start_time = timeit.default_timer()\n",
    "res = NN.train(X_train,y_train,0.0000001,2048,5,10**-3)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Time (minutes) elapsed for this cell:\", elapsed/60)\n",
    "print(\"Loss:\", res[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-7eb9401f9cdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
